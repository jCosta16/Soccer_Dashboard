{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import os\n",
    "from os.path  import basename\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import time\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "league_ID       int64\n",
       "country        object\n",
       "tier            int64\n",
       "league_name    object\n",
       "league_link    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leagues_df = pd.read_csv(\"data/leagues_data.csv\")\n",
    "leagues_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>league_ID</th>\n",
       "      <th>country</th>\n",
       "      <th>tier</th>\n",
       "      <th>league_name</th>\n",
       "      <th>league_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>BRAZIL</td>\n",
       "      <td>1</td>\n",
       "      <td>brasileiro_serie_a</td>\n",
       "      <td>https://www.transfermarkt.com/campeonato-brasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>BRAZIL</td>\n",
       "      <td>2</td>\n",
       "      <td>brasileiro_serie_b</td>\n",
       "      <td>https://www.transfermarkt.com/campeonato-brasi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>UNITED_STATES</td>\n",
       "      <td>1</td>\n",
       "      <td>major_league_soccer</td>\n",
       "      <td>https://www.transfermarkt.com/major-league-soc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>UNITED_STATES</td>\n",
       "      <td>2</td>\n",
       "      <td>USL_CHAMPIONSHIP</td>\n",
       "      <td>https://www.transfermarkt.com/usl-pro/startsei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   league_ID        country  tier          league_name  \\\n",
       "0          1         BRAZIL     1   brasileiro_serie_a   \n",
       "1          2         BRAZIL     2   brasileiro_serie_b   \n",
       "2          3  UNITED_STATES     1  major_league_soccer   \n",
       "3          4  UNITED_STATES     2     USL_CHAMPIONSHIP   \n",
       "\n",
       "                                         league_link  \n",
       "0  https://www.transfermarkt.com/campeonato-brasi...  \n",
       "1  https://www.transfermarkt.com/campeonato-brasi...  \n",
       "2  https://www.transfermarkt.com/major-league-soc...  \n",
       "3  https://www.transfermarkt.com/usl-pro/startsei...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leagues_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be able to scrape this website we need to use 'User Agents'\n",
    "# more info about user agents in 'https://webscraping.com/blog/User-agents/'\n",
    "# You can find your User-Agent at 'http://whatsmyuseragent.com/'\n",
    "headers = {'User-Agent': \n",
    "           'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_url = \"https://www.google.com/search?q=euro+to+dollar&oq=eur&aqs=chrome.1.69i57j35i39j0j46j0l2j69i61l2.2373j1j4&sourceid=chrome&ie=UTF-8\"\n",
    "html = requests.get(convert_url, headers=headers)\n",
    "soup = BeautifulSoup(html.content, 'html.parser')\n",
    "curr_value = soup.find('div', class_= \"b1hJbf\")\n",
    "curr_value = round(float(curr_value[\"data-exchange-rate\"]),2)\n",
    "\n",
    "def get_value_us(x):\n",
    "    value = []\n",
    "    for char in x:\n",
    "        value.append(char)\n",
    "    if value[-1] == \"m\":\n",
    "        float_value = \"\".join(value[1:-1])\n",
    "        return round(float(float_value)*curr_value,2)\n",
    "    else:\n",
    "        float_value = \"\".join(value[1:-3])\n",
    "        return round((float(float_value)*curr_value)/1000,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_league_data(leagues_df):\n",
    "    team_id = 1\n",
    "    team_ID = []\n",
    "    links = []\n",
    "    names = []\n",
    "    logos = []\n",
    "    squads = []\n",
    "    foreigners = []\n",
    "    total_MVs = []\n",
    "    avg_MVs = []\n",
    "    league_ID = []\n",
    "    \n",
    "    for index, row in leagues_df.iterrows():\n",
    "        url = row[\"league_link\"]\n",
    "        league_name = row[\"league_name\"]\n",
    "        tier = row[\"tier\"]\n",
    "        country = row[\"country\"]\n",
    "        league_id = row[\"league_ID\"]\n",
    "        print(f\"scraping: {country}_{tier}_{league_name}\")\n",
    "        html = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser')\n",
    "        htmltable = soup.find('table', class_= \"items\")\n",
    "\n",
    "\n",
    "        results = htmltable.findAll(\"tr\", class_ =[\"odd\",\"even\"])\n",
    "\n",
    "\n",
    "        for result in results:\n",
    "            features = result.findAll(\"td\")\n",
    "            links.append((\"https://www.transfermarkt.com\"+result.find(\"a\", href=True)\\\n",
    "                          [\"href\"]+\"/plus/1\").replace(\"startseite\", \"kader\"))\n",
    "            logo = result.find(\"img\", src=True)[\"src\"]\n",
    "            logo = logo.split(\"?\")[0]\n",
    "            logo = logo.replace(\"tiny\", \"header\")\n",
    "            logos.append(logo)\n",
    "            name = features[1].text\n",
    "            names.append(name)\n",
    "            squad = features[3].text\n",
    "            squads.append(squad)\n",
    "            foreigner = features[5].text\n",
    "            foreigners.append(foreigner)\n",
    "            total_MV = get_value_us(features[6].text)\n",
    "            total_MVs.append(total_MV)\n",
    "#             print(features[7])\n",
    "            avg_MV = get_value_us(features[7].text)\n",
    "            avg_MVs.append(avg_MV)\n",
    "            team_ID.append(team_id)\n",
    "            league_ID.append(league_id)\n",
    "            team_id = team_id + 1\n",
    "\n",
    "            time.sleep(2)\n",
    "\n",
    "\n",
    "    # Create a Dataframe and export to a .csv file\n",
    "    df = pd.DataFrame(list(zip(team_ID, league_ID, names, squads, foreigners,avg_MVs, total_MVs, logos,links)), \\\n",
    "columns =[\"team_ID\", \"league_ID\",\"club\",\"squad\", \"foreigners\", \"avg_market_value_m\", \"total_MV_m\",'Logo_img', \"link_page\"]) \n",
    "    df['league_ID'] = df['league_ID'].astype(int)\n",
    "    df['team_ID'] = df['team_ID'].astype(int)\n",
    "\n",
    "    df.to_csv(f'data/teams_trmk.csv',index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_team_data(teams_df):\n",
    "    player_id = 1\n",
    "    name = []\n",
    "    player_page = []\n",
    "    position = []\n",
    "    Age = []\n",
    "    Nat = []\n",
    "    Height = []\n",
    "    foot = []\n",
    "    dt_joined = []\n",
    "    prev_team = []\n",
    "    contract_expires = []\n",
    "    market_value = []\n",
    "    team_ID = []\n",
    "    players_ID = []\n",
    "    \n",
    "\n",
    "    df_league = pd.read_csv(teams_df)\n",
    "    for index, row in df_league.iterrows():\n",
    "        team_id = row[\"team_ID\"]\n",
    "        team = row[\"link_page\"]\n",
    "        team_name = team.split('/')[-8]\n",
    "        print(team_name)\n",
    "        html = requests.get(team, headers=headers)\n",
    "        soup = BeautifulSoup(html.content, 'html.parser')\n",
    "        htmltable = soup.find('table', class_= \"items\")\n",
    "\n",
    "        results = htmltable.findAll(\"tr\", class_ =[\"odd\",\"even\"])\n",
    "\n",
    "\n",
    "        for result in results:\n",
    "            features = result.findAll(\"td\")\n",
    "\n",
    "            name_1 = features[2].find(\"img\", alt=True)[\"alt\"]\n",
    "\n",
    "            player_page.append(\"https://www.transfermarkt.com\" + features[3].find(\"a\", href=True)[\"href\"])\n",
    "\n",
    "            position_1 = features[4].text\n",
    "\n",
    "            try:\n",
    "                age_1 = int((features[5].text.split(\"(\",)[-1])[:-1])\n",
    "            except:\n",
    "                age_1 = \"\"\n",
    "\n",
    "            nat = features[6].img[\"alt\"]\n",
    "\n",
    "            try:\n",
    "                Height_1 = float((features[7].text.split(\" \")[0]).replace(\",\", \".\"))\n",
    "            except:\n",
    "                Height_1 = \"\"\n",
    "\n",
    "            foot_1 = features[8].text\n",
    "\n",
    "            dt_joined_1 = features[9].text\n",
    "            try:\n",
    "                dt_joined_1 = datetime.strptime(dt_joined_1, '%b %d, %Y').date()\n",
    "            except:\n",
    "                dt_joined_1 = \"\"\n",
    "\n",
    "            try:\n",
    "                prev_team_1 = features[10].img[\"alt\"]\n",
    "            except:\n",
    "                prev_team_1 = \"N.A.\"\n",
    "\n",
    "\n",
    "            contract_expires_1 = features[11].text\n",
    "            try:\n",
    "                contract_expires_1 = datetime.strptime(contract_expires_1, '%d.%m.%Y').date()\n",
    "            except:\n",
    "                contract_expires_1 = \"\"\n",
    "\n",
    "            try:\n",
    "                market_value_1 = get_value_us(features[12].text[:-2])\n",
    "            except:\n",
    "                market_value_1 = 0\n",
    "\n",
    "            name.append(name_1)\n",
    "            position.append(position_1)\n",
    "            Age.append(age_1)\n",
    "            Nat.append(nat)\n",
    "            Height.append(Height_1)\n",
    "            foot.append(foot_1)\n",
    "            dt_joined.append(dt_joined_1)\n",
    "            prev_team.append(prev_team_1)\n",
    "            contract_expires.append(contract_expires_1)\n",
    "            market_value.append(market_value_1)\n",
    "            team_ID.append(team_id)\n",
    "            players_ID.append(player_id)\n",
    "            player_id = player_id+1\n",
    "\n",
    "        time.sleep(randint(3,5))\n",
    "\n",
    "    df = pd.DataFrame(list(zip(players_ID, team_ID, name, position, Age,Nat, Height, foot,dt_joined,prev_team, contract_expires,\\\n",
    "                               market_value,player_page)), \n",
    "                      columns =[\"players_ID\", \"team_ID\",\"name\",\"position\", \"Age\", \"Nat\",\"Height\",\"foot\",'dt_joined',\"prev_team\", \\\n",
    "                                \"contract_expires\", \"market_value\",\"player_page\" ])\n",
    "    df['players_ID'] = df['players_ID'].astype(int)\n",
    "    df['team_ID'] = df['team_ID'].astype(int)\n",
    "    df['dt_joined'] = pd.to_datetime(df['dt_joined'])\n",
    "    df['contract_expires'] = pd.to_datetime(df['contract_expires'])\n",
    "\n",
    "    df.to_csv(f\"data/players_trmk.csv\" ,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_league_data(leagues_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flamengo-rio-de-janeiro\n",
      "se-palmeiras-sao-paulo\n",
      "gremio-foot-ball-porto-alegrense\n",
      "fc-sao-paulo\n",
      "corinthians-sao-paulo\n",
      "sc-internacional-porto-alegre\n",
      "fc-santos\n",
      "atletico-mineiro\n",
      "fluminense-football-club\n",
      "vasco-da-gama-rio-de-janeiro\n",
      "clube-atletico-paranaense\n",
      "ec-bahia\n",
      "botafogo-fr-rio-de-janeiro\n",
      "clube-atletico-bragantino-sp-\n",
      "coritiba-fc\n",
      "goias-esporte-clube\n",
      "sport-club-do-recife\n",
      "ceara-sporting-club-ce-\n",
      "fortaleza-esporte-clube\n",
      "atletico-goianiense\n",
      "ec-cruzeiro-belo-horizonte\n",
      "avai-futebol-clube-sc-\n",
      "centro-sportivo-alagoano-al-\n",
      "clube-de-regatas-brasil-al-\n",
      "associacao-atletica-ponte-preta\n",
      "associacao-chapecoense-de-futebol\n",
      "esporte-clube-vitoria\n",
      "esporte-clube-juventude\n",
      "figueirense-futebol-clube\n",
      "america-futebol-clube-mg-\n",
      "clube-nautico-capibaribe\n",
      "botafogo-futebol-clube-sp-\n",
      "guarani-futebol-clube-sp-\n",
      "cuiaba-esporte-clube-mt-\n",
      "parana-clube\n",
      "gremio-esportivo-brasil-rs-\n",
      "oeste-futebol-clube-sp-\n",
      "operario-ferroviario-esporte-clube-pr-\n",
      "associacao-desportiva-confianca-se-\n",
      "sampaio-correa-futebol-clube-ma-\n",
      "los-angeles-football-club\n",
      "atlanta-united-fc\n",
      "inter-miami-cf\n",
      "los-angeles-galaxy\n",
      "toronto-fc\n",
      "new-york-city-fc\n",
      "seattle-sounders-fc\n",
      "sporting-kansas-city\n",
      "portland-timbers\n",
      "columbus-crew\n",
      "fc-cincinnati\n",
      "chicago-fire\n",
      "d-c-united\n",
      "new-york-red-bulls\n",
      "montreal-impact\n",
      "orlando-city-sc\n",
      "fc-dallas\n",
      "new-england-revolution\n",
      "houston-dynamo\n",
      "colorado-rapids\n",
      "vancouver-whitecaps\n",
      "minnesota-united-fc\n",
      "san-jose-earthquakes\n",
      "philadelphia-union\n",
      "real-salt-lake-city\n",
      "nashville-mls-team\n",
      "san-antonio-fc\n",
      "arizona-united-soccer-club\n",
      "seattle-sounders-fc-2\n",
      "indy-eleven\n",
      "louisville-city-fc\n",
      "austin-bold-fc\n",
      "oklahoma-city-energy-fc\n",
      "colorado-springs-switchbacks\n",
      "tampa-bay-rowdies\n",
      "sacramento-republic-fc\n",
      "tulsa-roughnecks\n",
      "miami-fc\n",
      "memphis-901-fc\n",
      "new-mexico-united\n",
      "orange-county-blues\n",
      "saint-louis-fc\n",
      "el-paso-usl\n",
      "san-diego-loyal-sc\n",
      "carolina-railhawks\n",
      "charleston-battery\n",
      "charlotte-independence\n",
      "pittsburgh-riverhounds\n",
      "birmingham-legion-fc\n",
      "reno-1868-fc\n",
      "portland-timbers-2\n",
      "real-monarchs\n",
      "las-vegas-lights-fc\n",
      "hartford-athletic\n",
      "rgv-fc-toros\n",
      "swope-park-rangers\n",
      "loudoun-united\n",
      "bethlehem-steel-fc\n",
      "los-angeles-galaxy-ii\n",
      "new-york-red-bulls-u23\n",
      "atlanta-united-2\n"
     ]
    }
   ],
   "source": [
    "teams_df = \"data/teams_trmk.csv\"\n",
    "\n",
    "scrape_team_data(teams_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \\\n",
    " \\\n",
    "  \\\n",
    "  \\\n",
    "  \\\n",
    "  \\\n",
    "  \\.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teams_df = \"data/BRAZIL_1_BRA_A_trmk.csv\"\n",
    "\n",
    "# scrape_team_data1(teams_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bra_1= pd.read_csv(\"data/teams_trmk.csv\")\n",
    "# bra_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bra_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bra_1[\"club\"] = bra_1[\"club\"].astype(str)\n",
    "# # bra_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files = glob('data/*.csv', recursive=True)\n",
    "# scrape_team_data1(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_league = pd.read_csv(teams_df)\n",
    "# df_league"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-15\n",
      "2024-12-30\n",
      "2024-06-30\n"
     ]
    }
   ],
   "source": [
    "contratcs = [\"15.06.2024\", \"30.12.2024\", \"30.06.2024\"]\n",
    "\n",
    "for contratc in contratcs:\n",
    "#     try:\n",
    "# #         contratc_expires_1 = datetime.strptime(contratc, '%d.%m.%Y').date()\n",
    "#         dt_joined_1 = datetime.strptime(contratc, '%b %d, %Y').date()\n",
    "#     except:\n",
    "# #         contract_expires_1 = \"01/01/2030\"\n",
    "#         dt_joined_1 = \"2019-01-01\"\n",
    "    try:\n",
    "        contratc_expires_1 = datetime.strptime(contratc, '%d.%m.%Y').date()\n",
    "#         dt_joined_1 = datetime.strptime(contratc, '%b %d, %Y').date()\n",
    "    except:\n",
    "        contract_expires_1 = \"2030-01-01\"\n",
    "#         dt_joined_1 = \"01/01/2019\"\n",
    "\n",
    "    print(contratc_expires_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fla= pd.read_csv(\"data/players_trmk.csv\")\n",
    "# fla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fla.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goias = \"https://www.transfermarkt.com/clube-de-regatas-do-flamengo/kader/verein/614/saison_id/2019/plus/1\"\n",
    "# team_name = goias.split('/')[-8]\n",
    "# print(f\"scraping: {team_name}\")\n",
    "# team_id\n",
    "      \n",
    "\n",
    "# html = requests.get(goias, headers=headers)\n",
    "# soup = BeautifulSoup(html.content, 'html.parser')\n",
    "# htmltable = soup.find('table', class_= \"items\")\n",
    "\n",
    "# results = htmltable.findAll(\"tr\", class_ =[\"odd\",\"even\"])\n",
    "\n",
    "# player_id = 1\n",
    "# team_id = 1\n",
    "# name = []\n",
    "# player_page = []\n",
    "# position = []\n",
    "# Age = []\n",
    "# Nat = []\n",
    "# Height = []\n",
    "# foot = []\n",
    "# dt_joined = []\n",
    "# prev_team = []\n",
    "# contract_expires = []\n",
    "# market_value = []\n",
    "# team_ID = []\n",
    "# players_ID = []\n",
    "\n",
    "\n",
    "# for result in results:\n",
    "#     features = result.findAll(\"td\")\n",
    "\n",
    "#     name_1 = features[2].find(\"img\", alt=True)[\"alt\"]\n",
    "\n",
    "#     player_page.append(\"https://www.transfermarkt.com\" + features[3].find(\"a\", href=True)[\"href\"])\n",
    "\n",
    "#     position_1 = features[4].text\n",
    "\n",
    "#     try:\n",
    "#         age_1 = int((features[5].text.split(\"(\",)[-1])[:-1])\n",
    "#     except:\n",
    "#         age_1 = \"-\"\n",
    "\n",
    "#     nat = features[6].img[\"alt\"]\n",
    "\n",
    "#     try:\n",
    "#         Height_1 = float((features[7].text.split(\" \")[0]).replace(\",\", \".\"))\n",
    "#     except:\n",
    "#         Height_1 = \"0\"\n",
    "\n",
    "#     foot_1 = features[8].text\n",
    "\n",
    "#     dt_joined_1 = features[9].text\n",
    "#     try:\n",
    "#         dt_joined_1 = datetime.strptime(dt_joined_1, '%b %d, %Y').date()\n",
    "#     except:\n",
    "#         dt_joined_1 = \"2019-01-01\"\n",
    "\n",
    "#     try:\n",
    "#         prev_team_1 = features[10].img[\"alt\"]\n",
    "#     except:\n",
    "#         prev_team_1 = \"-\"\n",
    "\n",
    "\n",
    "#     contract_expires_1 = features[11].text\n",
    "#     try:\n",
    "#         contratc_expires_1 = datetime.strptime(contratc_expires_1, '%d.%m.%Y').date()\n",
    "#     except:\n",
    "#         contract_expires_1 = \"2030-01-01\"\n",
    "\n",
    "\n",
    "#     try:\n",
    "#         market_value_1 = get_value_us(features[12].text[:-2])\n",
    "#     except:\n",
    "#         market_value_1 = 0\n",
    "\n",
    "#     name.append(name_1)\n",
    "#     position.append(position_1)\n",
    "#     Age.append(age_1)\n",
    "#     Nat.append(nat)\n",
    "#     Height.append(Height_1)\n",
    "#     foot.append(foot_1)\n",
    "#     dt_joined.append(dt_joined_1)\n",
    "#     prev_team.append(prev_team_1)\n",
    "#     contract_expires.append(contract_expires_1)\n",
    "#     market_value.append(market_value_1)\n",
    "#     team_ID.append(team_id)\n",
    "#     players_ID.append(player_id)\n",
    "#     player_id = player_id+1\n",
    "    \n",
    "# df = pd.DataFrame(list(zip(players_ID, team_ID, name, position, Age,Nat, Height, foot,dt_joined,prev_team, contract_expires,\\\n",
    "#                            market_value,player_page)), \n",
    "#                   columns =[\"players_ID\", \"team_ID\",\"name\",\"position\", \"Age\", \"Nat\",\"Height\",\"foot\",'dt_joined',\"prev_team\", \\\n",
    "#                             \"contract_expires\", \"market_value\",\"player_page\" ])\n",
    "# df['players_ID'] = df['players_ID'].astype(int)\n",
    "# df['team_ID'] = df['team_ID'].astype(int)\n",
    "# df['dt_joined'] = pd.to_datetime(df['dt_joined'])\n",
    "# df['contract_expires'] = pd.to_datetime(df['contract_expires'])\n",
    "\n",
    " \n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "\n",
    "# df_copy = df.copy()\n",
    "\n",
    "# for date in df_copy[\"contract_expires\"]:\n",
    "#     try:\n",
    "#         date = datetime.strptime(date, '%d.%m.%Y').date()\n",
    "#     except:\n",
    "#         date = '-' \n",
    "#     print(date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fla_copy = fla.copy()\n",
    "\n",
    "# for date in fla_copy[\"dt_joined\"]:\n",
    "#     try:\n",
    "#         date = datetime.strptime(date, '%b %d, %Y').date()\n",
    "#     except:\n",
    "#         date = \"-\"\n",
    "#     print(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name_1 = features[2].find(\"img\", alt=True)[\"alt\"]\n",
    "# position_1 = features[4].text\n",
    "# DoB_1 = int((features[5].text.split(\"(\",)[-1])[:-1])\n",
    "# nat = features[6].img[\"alt\"]\n",
    "# Height_1 = float((features[7].text.split(\" \")[0]).replace(\",\", \".\"))\n",
    "# foot_1 = features[8].text\n",
    "# dt_joined_1 = features[9].text\n",
    "# prev_team_1 = features[10].img[\"alt\"]\n",
    "# contract_expires_1 = features[11].text\n",
    "# market_value_1 = get_value_us(features[12].text[:-2])\n",
    "\n",
    "# print(name_1, position_1,DoB_1, nat, Height_1,foot_1,dt_joined_1,prev_team_1,contract_expires_1,market_value_1   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(\"data/teams/goias-esporte-clube_trmk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Retrieve page with the requests module\n",
    "# url = \"https://www.transfermarkt.com/major-league-soccer/startseite/wettbewerb/MLS1\"\n",
    "# html = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create BeautifulSoup object; parse with 'html.parser'\n",
    "# soup = BeautifulSoup(html.content, 'html.parser')\n",
    "# htmltable = soup.find('table', class_= \"items\")\n",
    "# text1 = htmltable.text\n",
    "# text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Examine the results, then determine element that contains sought info\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = htmltable.findAll(\"tr\", class_ =[\"odd\",\"even\"])\n",
    "# print(results[0])\n",
    "# print(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # to Download imgs\n",
    "# for img in logos:\n",
    "#         with open(basename(img), \"wb\") as f:\n",
    "#             f.write(requests.get(img).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names= []\n",
    "# for result in results:\n",
    "#     names.append(result.find(\"img\", alt=True)[\"alt\"])\n",
    "    \n",
    "# names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extrating a table from HTML\n",
    "# htmltable2 = str(htmltable)\n",
    "# dfs = pd.read_html(htmltable2)\n",
    "# df_clean = dfs[0][[\"Club.1\",\"name.1\", \"ø age\", \"Total market value\", \"ø market value\" ]]\n",
    "# df_clean = df_clean.drop(df_clean.index[len(df_clean.index)-1])\n",
    "# df = df_clean.set_axis([\"Club\",\"Squad\", \"Foreigners\", \"avg_market_value\" , \"total_market_value\"], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<td class=\"zentriert no-border-rechts\">\n",
    "    <a class=\"vereinprofil_tooltip\" href=\"/los-angeles-football-club/startseite/verein/51828/saison_id/2019\">\n",
    "        <img alt=\"Los Angeles FC\" class=\"tiny_wappen\" src=\"https://tmssl.akamaized.net//images/wappen/tiny/51828.png?lm=1511112738\" title=\" \"/>\n",
    "    </a>\n",
    "</td>\n",
    "<td class=\"hauptlink no-border-links hide-for-small hide-for-pad\">\n",
    "    <a class=\"vereinprofil_tooltip\" href=\"/los-angeles-football-club/startseite/verein/51828/saison_id/2019\" id=\"51828\">\n",
    "        Los Angeles FC\n",
    "    </a>\n",
    "</td>\n",
    "<td class=\"hauptlink no-border-links show-for-small show-for-pad\">\n",
    "    <a class=\"vereinprofil_tooltip\" href=\"/los-angeles-football-club/startseite/verein/51828/saison_id/2019\" id=\"51828\">\n",
    "        Los Angeles FC\n",
    "    </a>\n",
    "</td>\n",
    "<td class=\"zentriert\">\n",
    "    <a href=\"/los-angeles-fc/kader/verein/51828/saison_id/2019\" title=\"Los Angeles FC\">\n",
    "    24\n",
    "    </a>\n",
    "</td>\n",
    "<td class=\"zentriert hide-for-small hide-for-pad\">\n",
    "    26,1\n",
    "</td>\n",
    "<td class=\"zentriert hide-for-pad hide-for-small\">\n",
    "    17\n",
    "</td>\n",
    "<td class=\"rechts hide-for-small hide-for-pad\">\n",
    "    <a href=\"/los-angeles-fc/kader/verein/51828/saison_id/2019\" title=\"Los Angeles FC\">\n",
    "    €49.20m\n",
    "    </a>\n",
    "</td>\n",
    "<td class=\"rechts hide-for-small hide-for-pad\">\n",
    "    €2.05m\n",
    "</td>\n",
    "<td class=\"rechts show-for-small show-for-pad nowrap\">\n",
    "    <a href=\"/los-angeles-fc/kader/verein/51828/saison_id/2019\" title=\"Los Angeles FC\">\n",
    "        €49.20m\n",
    "    </a>\n",
    "</td>\n",
    "<td class=\"rechts show-for-small show-for-pad nowrap\">\n",
    "    €2.05m\n",
    "</td>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_value(x):\n",
    "#     value = []\n",
    "#     for char in x:\n",
    "#         value.append(char)\n",
    "#     float_value = \"\".join(value[1:-1])\n",
    "#     return float(float_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_value(fdf[6].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # URLs of page to be scraped\n",
    "# bra = {\"BRAZIL\": {\"leagues\":[{\"tier_1\":'https://www.transfermarkt.com/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA1'},\n",
    "#                  {\"tier_2\": \"https://www.transfermarkt.com/campeonato-brasileiro-serie-a/startseite/wettbewerb/BRA2\"}]}},\n",
    "# us = {\"UNITED_STATES\": {\"leagues\":[{\"tier_1\": \"https://www.transfermarkt.com/major-league-soccer/startseite/wettbewerb/MLS1\"},\n",
    "#                   {\"tier_2\":\"https://www.transfermarkt.com/usl-pro/startseite/wettbewerb/USL\"}, \n",
    "#                   {\"tier_3\":\"https://www.transfermarkt.com/usl-league-one/startseite/wettbewerb/USC3\"}]}}\n",
    "# urls= [bra, us]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_league_data(leagues_df):\n",
    "#     team_id = 1\n",
    "#     for index, row in leagues_df.iterrows():\n",
    "#         url = row[\"league_link\"]\n",
    "#         league_name = row[\"league_name\"]\n",
    "#         tier = row[\"tier\"]\n",
    "#         country = row[\"country\"]\n",
    "#         league_id = row[\"league_ID\"]\n",
    "#         print(f\"scraping: {country}_{tier}_{league_name}\")\n",
    "#         html = requests.get(url, headers=headers)\n",
    "#         soup = BeautifulSoup(html.content, 'html.parser')\n",
    "#         htmltable = soup.find('table', class_= \"items\")\n",
    "\n",
    "\n",
    "#         results = htmltable.findAll(\"tr\", class_ =[\"odd\",\"even\"])\n",
    "\n",
    "\n",
    "#         team_ID = []\n",
    "#         links = []\n",
    "#         names = []\n",
    "#         logos = []\n",
    "#         squads = []\n",
    "#         foreigners = []\n",
    "#         total_MVs = []\n",
    "#         avg_MVs = []\n",
    "#         league_ID = []\n",
    "\n",
    "\n",
    "\n",
    "#         for result in results:\n",
    "#             features = result.findAll(\"td\")\n",
    "#             links.append((\"https://www.transfermarkt.com\"+result.find(\"a\", href=True)\\\n",
    "#                           [\"href\"]+\"/plus/1\").replace(\"startseite\", \"kader\"))\n",
    "#             logo = result.find(\"img\", src=True)[\"src\"]\n",
    "#             logo = logo.split(\"?\")[0]\n",
    "#             logo = logo.replace(\"tiny\", \"header\")\n",
    "#             logos.append(logo)\n",
    "#             name = features[1].text\n",
    "#             names.append(name)\n",
    "#             squad = features[3].text\n",
    "#             squads.append(squad)\n",
    "#             foreigner = features[5].text\n",
    "#             foreigners.append(foreigner)\n",
    "#             total_MV = get_value_us(features[6].text)\n",
    "#             total_MVs.append(total_MV)\n",
    "#             avg_MV = get_value_us(features[7].text)\n",
    "#             avg_MVs.append(avg_MV)\n",
    "#             team_ID.append(team_id)\n",
    "#             league_ID.append(league_id)\n",
    "#             team_id = team_id + 1\n",
    "\n",
    "\n",
    "\n",
    "#         # Create a Dataframe and export to a .csv file\n",
    "#         df = pd.DataFrame(list(zip(team_ID, league_ID, names, squads, foreigners,avg_MVs, total_MVs, logos,links)), \\\n",
    "#     columns =[\"team_ID\", \"league_ID\",\"club\",\"squad\", \"foreigners\", \"avg_market_value_m\", \"total_MV_m\",'Logo_img', \"link_page\"]) \n",
    "#         df['league_ID'] = df['league_ID'].astype(int)\n",
    "#         df['team_ID'] = df['team_ID'].astype(int)\n",
    "\n",
    "#         df.to_csv(f'data/{country}_{tier}_{league_name}_trmk.csv',index=False)\n",
    "\n",
    "\n",
    "#         time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scrape_team_data(files):\n",
    "#     player_id = 1\n",
    "#     for filename in files:\n",
    "#         print(filename)\n",
    "#         time.sleep(5)\n",
    "#         df_league = pd.read_csv(filename)\n",
    "#         for index, row in df_league.iterrows():\n",
    "#             team_id = row[\"team_ID\"]\n",
    "#             team = row[\"link_page\"]\n",
    "#             team_name = team.split('/')[-8]\n",
    "#             print(team_name)\n",
    "#             html = requests.get(team, headers=headers)\n",
    "#             soup = BeautifulSoup(html.content, 'html.parser')\n",
    "#             htmltable = soup.find('table', class_= \"items\")\n",
    "\n",
    "#             results = htmltable.findAll(\"tr\", class_ =[\"odd\",\"even\"])\n",
    "#             name = []\n",
    "#             player_page = []\n",
    "#             position = []\n",
    "#             Age = []\n",
    "#             Nat = []\n",
    "#             Height = []\n",
    "#             foot = []\n",
    "#             dt_joined = []\n",
    "#             prev_team = []\n",
    "#             contract_expires = []\n",
    "#             market_value = []\n",
    "#             team_ID = []\n",
    "#             players_ID = []\n",
    "\n",
    "#             for result in results:\n",
    "#                 features = result.findAll(\"td\")\n",
    "\n",
    "#                 name_1 = features[2].find(\"img\", alt=True)[\"alt\"]\n",
    "\n",
    "#                 player_page.append(\"https://www.transfermarkt.com\" + features[3].find(\"a\", href=True)[\"href\"])\n",
    "\n",
    "#                 position_1 = features[4].text\n",
    "\n",
    "#                 try:\n",
    "#                     age_1 = int((features[5].text.split(\"(\",)[-1])[:-1])\n",
    "#                 except:\n",
    "#                     age_1 = \"-\"\n",
    "\n",
    "#                 nat = features[6].img[\"alt\"]\n",
    "\n",
    "#                 try:\n",
    "#                     Height_1 = float((features[7].text.split(\" \")[0]).replace(\",\", \".\"))\n",
    "#                 except:\n",
    "#                     Height_1 = \"m\"\n",
    "\n",
    "#                 foot_1 = features[8].text\n",
    "\n",
    "#                 dt_joined_1 = features[9].text\n",
    "#                 try:\n",
    "#                     dt_joined_1 = datetime.strptime(dt_joined_1, '%b %d, %Y').date()\n",
    "#                 except:\n",
    "#                     dt_joined_1 = \"-\"\n",
    "\n",
    "#                 try:\n",
    "#                     prev_team_1 = features[10].img[\"alt\"]\n",
    "#                 except:\n",
    "#                     prev_team_1 = \"-\"\n",
    "\n",
    "\n",
    "#                 contract_expires_1 = features[11].text\n",
    "#                 try:\n",
    "#                     contratc_expires_1 = datetime.strptime(contratc_expires_1, '%d.%m.%Y').date()\n",
    "#                 except:\n",
    "#                     contract_expires_1 = features[11].text\n",
    "\n",
    "\n",
    "#                 try:\n",
    "#                     market_value_1 = get_value_us(features[12].text[:-2])\n",
    "#                 except:\n",
    "#                     market_value_1 = 0\n",
    "\n",
    "#                 name.append(name_1)\n",
    "#                 position.append(position_1)\n",
    "#                 Age.append(age_1)\n",
    "#                 Nat.append(nat)\n",
    "#                 Height.append(Height_1)\n",
    "#                 foot.append(foot_1)\n",
    "#                 dt_joined.append(dt_joined_1)\n",
    "#                 prev_team.append(prev_team_1)\n",
    "#                 contract_expires.append(contract_expires_1)\n",
    "#                 market_value.append(market_value_1)\n",
    "#                 team_ID.append(team_id)\n",
    "#                 players_ID.append(player_id)\n",
    "#                 player_id = player_id+1\n",
    "\n",
    "#             df = pd.DataFrame(list(zip(players_ID, team_ID, name, position, Age,Nat, Height, foot,dt_joined,prev_team, contract_expires,\\\n",
    "#                                        market_value,player_page)), \n",
    "#                               columns =[\"players_ID\", \"team_ID\",\"name\",\"position\", \"Age\", \"Nat\",\"Height\",\"foot\",'dt_joined',\"prev_team\", \\\n",
    "#                                         \"contract_expires\", \"market_value\",\"player_page\" ])\n",
    "#             df['players_ID'] = df['players_ID'].astype(int)\n",
    "#             df['team_ID'] = df['team_ID'].astype(int)\n",
    "            \n",
    "\n",
    "#             df.to_csv(f\"data/teams/{team_name}_trmk.csv\" ,index=False)\n",
    "#             time.sleep(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
